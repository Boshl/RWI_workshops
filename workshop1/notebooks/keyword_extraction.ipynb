{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Extraction\n",
    "\n",
    "- Keyword Extraction ist die Extraktion von relevanten Schlüsselwörtern aus Dokumenten in Textform.\n",
    "- Eine Sammlung aus Dokumenten wird dabei als Korpus bezeichnet.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiere benötigte Bibliotheken\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import operator\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiere einen Textkorpus\n",
    "corpus = [\n",
    "    'Das ist das erste Dokument. Das Thema heute ist die Vorverarbeitung von Texten. Die Vorverarbeitung ist ein wichtiges Konzept der Sprachverarbeitung.',\n",
    "    'Dieses Dokument ist das zweite Dokument. Mit diesem Dokument soll ebenfalls gearbeitet werden.',\n",
    "    'Dies ist das dritte Dokument. Somit sind mindestens drei Dokumente vorhanden.',\n",
    "    'Ist dieses Dokument das Erste?'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency (Vorkommenhäufigkeit)\n",
    "- Gibt an, wie häufig ein Ausdruck in einem Dokument vorkommt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ist</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Das</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vorverarbeitung</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ein</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heute</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Die</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>die</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>der</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>das</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Thema</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Texten</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sprachverarbeitung</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Konzept</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>von</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dokument</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wichtiges</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>erste</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mindestens</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sind</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>soll</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vorhanden</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>werden</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gearbeitet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>diesem</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ebenfalls</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>dritte</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>drei</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>dieses</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Somit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Mit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Ist</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Erste</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Dokumente</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Dieses</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Dies</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>zweite</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               keyword  frequency\n",
       "0                  ist          3\n",
       "1                  Das          2\n",
       "2      Vorverarbeitung          2\n",
       "3                  ein          1\n",
       "4                heute          1\n",
       "5                  Die          1\n",
       "6                  die          1\n",
       "7                  der          1\n",
       "8                  das          1\n",
       "9                Thema          1\n",
       "10              Texten          1\n",
       "11  Sprachverarbeitung          1\n",
       "12             Konzept          1\n",
       "13                 von          1\n",
       "14            Dokument          1\n",
       "15           wichtiges          1\n",
       "16               erste          1\n",
       "17          mindestens          0\n",
       "18                sind          0\n",
       "19                soll          0\n",
       "20           vorhanden          0\n",
       "21              werden          0\n",
       "22          gearbeitet          0\n",
       "23              diesem          0\n",
       "24           ebenfalls          0\n",
       "25              dritte          0\n",
       "26                drei          0\n",
       "27              dieses          0\n",
       "28               Somit          0\n",
       "29                 Mit          0\n",
       "30                 Ist          0\n",
       "31               Erste          0\n",
       "32           Dokumente          0\n",
       "33              Dieses          0\n",
       "34                Dies          0\n",
       "35              zweite          0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Erstelle einen Vektor für die Vorkommenshäufigkeiten\n",
    "vectorizer = CountVectorizer(lowercase=False)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "term_frequencies = X.toarray()\n",
    "# Übertrage Ergebnisse in ein Dictionary und dann DataFrame\n",
    "data = {'keyword' : feature_names, 'frequency': term_frequencies[0]}\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "df = df.sort_values(by=['frequency'], ascending=False)\n",
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frage: Welche Probleme sind bei dieser Auswertung erkennbar? \n",
    "(Lösung: Folie 18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Das Tf-idf-Maß\n",
    "- Geeigneteres Bewertungsschema als die einfache Vorkommenshäufigkeit\n",
    "- Statistisches Maß zur Beurteilung der Relevanz von Termen in Dokumenten eines Korpus\n",
    "- Setzt sich aus term frequency (Vorkommenshäufigkeit) und inverse document frequency (Inverse Dokumentenhäufigkeit) zusammen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>tfidf_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Das</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vorverarbeitung</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ist</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ein</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heute</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Die</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>die</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>der</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Thema</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Texten</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sprachverarbeitung</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Konzept</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>von</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wichtiges</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>erste</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>das</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Dokument</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mindestens</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sind</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>soll</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vorhanden</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>werden</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gearbeitet</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>diesem</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ebenfalls</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>dritte</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>drei</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>dieses</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Somit</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Mit</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Ist</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Erste</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Dokumente</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Dieses</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Dies</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>zweite</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               keyword  tfidf_score\n",
       "0                  Das         0.41\n",
       "1      Vorverarbeitung         0.41\n",
       "2                  ist         0.39\n",
       "3                  ein         0.20\n",
       "4                heute         0.20\n",
       "5                  Die         0.20\n",
       "6                  die         0.20\n",
       "7                  der         0.20\n",
       "8                Thema         0.20\n",
       "9               Texten         0.20\n",
       "10  Sprachverarbeitung         0.20\n",
       "11             Konzept         0.20\n",
       "12                 von         0.20\n",
       "13           wichtiges         0.20\n",
       "14               erste         0.20\n",
       "15                 das         0.11\n",
       "16            Dokument         0.11\n",
       "17          mindestens         0.00\n",
       "18                sind         0.00\n",
       "19                soll         0.00\n",
       "20           vorhanden         0.00\n",
       "21              werden         0.00\n",
       "22          gearbeitet         0.00\n",
       "23              diesem         0.00\n",
       "24           ebenfalls         0.00\n",
       "25              dritte         0.00\n",
       "26                drei         0.00\n",
       "27              dieses         0.00\n",
       "28               Somit         0.00\n",
       "29                 Mit         0.00\n",
       "30                 Ist         0.00\n",
       "31               Erste         0.00\n",
       "32           Dokumente         0.00\n",
       "33              Dieses         0.00\n",
       "34                Dies         0.00\n",
       "35              zweite         0.00"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_tfidf_rankings(corpus):\n",
    "    # Bilde einen Tfidf Vektor\n",
    "    vectorizer = TfidfVectorizer(lowercase=False)\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    term_frequencies = X.toarray()\n",
    "    # Übertrage Ergebnisse in ein Dictionary und dann Dataframe\n",
    "    data = {'keyword' : feature_names, 'tfidf_score': term_frequencies[0]}\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    df = df.sort_values(by=['tfidf_score'], ascending=False)\n",
    "    df = df.reset_index(drop=True).round(2)\n",
    "    return df\n",
    "\n",
    "get_tfidf_rankings(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorverarbeitung (Preprocessing):\n",
    "- Ziel: Reduktion der Dimensionen und entfernen von fehlerhaften Zeichen etc.\n",
    "- Groß-/Kleinschreibung sollte unerheblich sein, da sie keinen Einfluss auf die Semantik hat (\"Das\"/\"das\" oder \"Erste\"/\"erste\") \n",
    "- Unwichtige Wörter wie z.B. \"Der\" oder \"Die\" könnten rausgefilter werden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatisierung (Lemmatization)\n",
    "- Grundform eines Wortes, die im Lexikon abgebildet ist\n",
    "- Hilfreich für Dimensionsreduktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "der sein der erster Dokument -- der Thema heute sein der Vorverarbeitung von Text -- der Vorverarbeitung sein ein wichtig Konzept der Sprachverarbeitung -- \n",
      "dieser Dokument sein der zweiter Dokument -- mit dieser Dokument sollen ebenfalls arbeiten werden -- \n",
      "dieser sein der dritter Dokument -- somit sein mindestens drei Dokument vorhanden -- \n",
      "sein dieser Dokument der erster -- \n"
     ]
    }
   ],
   "source": [
    "def lemmatize(document):\n",
    "    nlp = spacy.load('de_core_news_sm')\n",
    "    lemmatized = \"\"\n",
    "    document = nlp(document)\n",
    "    for word in document:\n",
    "        lemmatized += word.lemma_ + \" \"\n",
    "    return lemmatized\n",
    "\n",
    "corpus_lemmatized = []\n",
    "for document in corpus:\n",
    "    lemmatized = lemmatize(document)\n",
    "    print(lemmatized)\n",
    "    corpus_lemmatized.append(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>tfidf_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>der</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vorverarbeitung</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sein</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ein</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Konzept</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sprachverarbeitung</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Text</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thema</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wichtig</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>von</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>heute</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>erster</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dokument</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ebenfalls</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dritter</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mindestens</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mit</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>drei</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sollen</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>somit</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>dieser</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vorhanden</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>werden</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>arbeiten</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>zweiter</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               keyword  tfidf_score\n",
       "0                  der         0.62\n",
       "1      Vorverarbeitung         0.40\n",
       "2                 sein         0.31\n",
       "3                  ein         0.20\n",
       "4              Konzept         0.20\n",
       "5   Sprachverarbeitung         0.20\n",
       "6                 Text         0.20\n",
       "7                Thema         0.20\n",
       "8              wichtig         0.20\n",
       "9                  von         0.20\n",
       "10               heute         0.20\n",
       "11              erster         0.16\n",
       "12            Dokument         0.10\n",
       "13           ebenfalls         0.00\n",
       "14             dritter         0.00\n",
       "15          mindestens         0.00\n",
       "16                 mit         0.00\n",
       "17                drei         0.00\n",
       "18              sollen         0.00\n",
       "19               somit         0.00\n",
       "20              dieser         0.00\n",
       "21           vorhanden         0.00\n",
       "22              werden         0.00\n",
       "23            arbeiten         0.00\n",
       "24             zweiter         0.00"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = corpus_lemmatized\n",
    "get_tfidf_rankings(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entfernen von Stoppwörtern (Stopwords)\n",
    "- Stoppwörter tragen nicht zur Bedeutung / Semantik der Sätze bei\n",
    "- Stoppwörter sind Füllwörter wie Artikel \"der, die, das\" oder \"und, ist\" etc.\n",
    "- Da sie keine Relevanz in Bezug auf die Extraktion von Schlüsselwörtern haben, können sie herausgefiltert werden "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "der sein der erster Dokument -- der Thema heute sein der Vorverarbeitung von Text -- der Vorverarbeitung sein ein wichtig Konzept der Sprachverarbeitung -- \n",
      "dieser Dokument sein der zweiter Dokument -- mit dieser Dokument sollen ebenfalls arbeiten werden -- \n",
      "dieser sein der dritter Dokument -- somit sein mindestens drei Dokument vorhanden -- \n",
      "sein dieser Dokument der erster -- \n"
     ]
    }
   ],
   "source": [
    "def remove_stop_words(document):\n",
    "    stop_words = stopwords.words('german') # lädt Liste mit deutschen Stoppwörtern\n",
    "    tokenized = word_tokenize(document)\n",
    "    document_filtered = \"\"\n",
    "    for word in tokenized:\n",
    "        if word not in stop_words and word.isalpha(): # filtert Stoppwörter und Zeichen, die nicht im Alphabet sind raus\n",
    "            document_filtered += word + \" \"\n",
    "    return document_filtered\n",
    "\n",
    "corpus_filtered = []\n",
    "for document in corpus:\n",
    "    print(document)\n",
    "    corpus_filtered.append(remove_stop_words(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['erster Dokument Thema heute Vorverarbeitung Text Vorverarbeitung wichtig Konzept Sprachverarbeitung ', 'Dokument zweiter Dokument Dokument sollen ebenfalls arbeiten ', 'dritter Dokument somit mindestens drei Dokument vorhanden ', 'Dokument erster ']\n"
     ]
    }
   ],
   "source": [
    "corpus = corpus_filtered\n",
    "get_tfidf_rankings(corpus)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowercasing (Kleinschreibung)\n",
    "- Vereinheitlichung der Begriffe durch Kleinschreibung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erster dokument thema heute vorverarbeitung text vorverarbeitung wichtig konzept sprachverarbeitung \n",
      "dokument zweiter dokument dokument sollen ebenfalls arbeiten \n",
      "dritter dokument somit mindestens drei dokument vorhanden \n",
      "dokument erster \n"
     ]
    }
   ],
   "source": [
    "corpus_lowercase = []\n",
    "corpus_lowercase = list(map(lambda x: x.lower(), corpus))\n",
    "for document in corpus_lowercase:\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>tfidf_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vorverarbeitung</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sprachverarbeitung</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wichtig</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>heute</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>konzept</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>thema</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>text</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>erster</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dokument</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>arbeiten</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vorhanden</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sollen</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>somit</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mindestens</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ebenfalls</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dritter</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>drei</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>zweiter</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               keyword  tfidf_score\n",
       "0      vorverarbeitung         0.61\n",
       "1   sprachverarbeitung         0.30\n",
       "2              wichtig         0.30\n",
       "3                heute         0.30\n",
       "4              konzept         0.30\n",
       "5                thema         0.30\n",
       "6                 text         0.30\n",
       "7               erster         0.24\n",
       "8             dokument         0.16\n",
       "9             arbeiten         0.00\n",
       "10           vorhanden         0.00\n",
       "11              sollen         0.00\n",
       "12               somit         0.00\n",
       "13          mindestens         0.00\n",
       "14           ebenfalls         0.00\n",
       "15             dritter         0.00\n",
       "16                drei         0.00\n",
       "17             zweiter         0.00"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = corpus_lowercase\n",
    "get_tfidf_rankings(corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
